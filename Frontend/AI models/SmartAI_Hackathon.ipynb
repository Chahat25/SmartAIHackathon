{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "### **SKIN TONE DETECTION**"
      ],
      "metadata": {
        "id": "czbiDpPoIWme"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install mtcnn\n",
        "!pip install tensorflow==2.11.0"
      ],
      "metadata": {
        "id": "DeShdXvL0bgq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "766d7466-73ce-4f18-e779-1920cbe26d15"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting mtcnn\n",
            "  Downloading mtcnn-1.0.0-py3-none-any.whl.metadata (5.8 kB)\n",
            "Requirement already satisfied: joblib>=1.4.2 in /usr/local/lib/python3.10/dist-packages (from mtcnn) (1.4.2)\n",
            "Collecting lz4>=4.3.3 (from mtcnn)\n",
            "  Downloading lz4-4.3.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.7 kB)\n",
            "Downloading mtcnn-1.0.0-py3-none-any.whl (1.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.9/1.9 MB\u001b[0m \u001b[31m23.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading lz4-4.3.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m35.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: lz4, mtcnn\n",
            "Successfully installed lz4-4.3.3 mtcnn-1.0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**PRINTING THE SKIN COLOR**"
      ],
      "metadata": {
        "id": "mTwC0fZ_CpIW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import load_model\n",
        "from mtcnn import MTCNN\n",
        "from sklearn.cluster import KMeans\n",
        "\n",
        "# Load the trained model\n",
        "model = load_model('/content/model.h5')  # Replace with your model path\n",
        "\n",
        "# List of class names\n",
        "classes = ['Fair_Light', 'Medium_Tan', 'Dark_Deep']\n",
        "\n",
        "# Mapping dictionary for descriptive skin tone labels\n",
        "descriptive_labels = {\n",
        "    'Fair_Light': 'Fair / Light',\n",
        "    'Medium_Tan': 'Medium / Tan',\n",
        "    'Dark_Deep': 'Dark / Deep'\n",
        "}\n",
        "\n",
        "# Load the MTCNN face detection model\n",
        "mtcnn = MTCNN()\n",
        "\n",
        "\n",
        "def kmeans_dominant_color(image, k=3):\n",
        "    \"\"\"Extract the dominant color using K-Means clustering.\"\"\"\n",
        "    pixels = image.reshape(-1, 3)\n",
        "    kmeans = KMeans(n_clusters=k, random_state=42)\n",
        "    kmeans.fit(pixels)\n",
        "    dominant_color = kmeans.cluster_centers_[np.argmax(np.bincount(kmeans.labels_))]\n",
        "    return dominant_color.astype(int)\n",
        "\n",
        "    \"\"\"Extract skin regions and find the dominant color.\"\"\"\n",
        "    ycrcb = cv2.cvtColor(image, cv2.COLOR_BGR2YCrCb)\n",
        "    lower = np.array([0, 133, 77], dtype=np.uint8)\n",
        "    upper = np.array([255, 173, 127], dtype=np.uint8)\n",
        "    skin_mask = cv2.inRange(ycrcb, lower, upper)\n",
        "    skin_pixels = cv2.bitwise_and(image, image, mask=skin_mask)\n",
        "    dominant_color = np.mean(skin_pixels[skin_mask > 0], axis=0)\n",
        "    return dominant_color.astype(int)\n",
        "\n",
        "\n",
        "def predict_skin_tone(image_path):\n",
        "    try:\n",
        "        # Read the image\n",
        "        image = cv2.imread(image_path)\n",
        "        if image is None:\n",
        "            raise ValueError(\"Image could not be read. Check the file path.\")\n",
        "\n",
        "        # Detect faces\n",
        "        faces = mtcnn.detect_faces(image)\n",
        "        if len(faces) > 0:\n",
        "            # Select the largest face\n",
        "            largest_face = max(faces, key=lambda f: f['box'][2] * f['box'][3])\n",
        "            x, y, w, h = largest_face['box']\n",
        "            detected_face = image[y:y + h, x:x + w]\n",
        "\n",
        "            # Resize the detected face to the desired input shape\n",
        "            resized_face = cv2.resize(detected_face, (120, 90))\n",
        "\n",
        "            # Preprocess the detected face for classification\n",
        "            preprocessed_face = tf.keras.applications.mobilenet_v2.preprocess_input(resized_face[np.newaxis, ...])\n",
        "\n",
        "            # Predict the class of the face\n",
        "            predictions = model.predict(preprocessed_face)\n",
        "            predicted_class_idx = np.argmax(predictions)\n",
        "            predicted_class = classes[predicted_class_idx]\n",
        "\n",
        "            # Get the descriptive label from the mapping dictionary\n",
        "            descriptive_label = descriptive_labels[predicted_class]\n",
        "            print(f'Predicted Skin Tone: {descriptive_label}')\n",
        "\n",
        "            # Save the dominant colors using each method\n",
        "            # 1. K-Means Clustering\n",
        "            kmeans_color = kmeans_dominant_color(detected_face)\n",
        "            kmeans_square = np.full((100, 100, 3), kmeans_color, dtype=np.uint8)\n",
        "            kmeans_path = \"/content/color_result/kmeans_dominant_color.jpg\"\n",
        "            cv2.imwrite(kmeans_path, kmeans_square)\n",
        "            print(f\"K-Means Dominant Color (BGR): {kmeans_color}\")\n",
        "            print(f\"Saved to: {kmeans_path}\")\n",
        "\n",
        "        else:\n",
        "            print('No face detected in the uploaded image.')\n",
        "    except Exception as e:\n",
        "        print(f'Error processing the image: {e}')\n",
        "\n",
        "\n",
        "# Prompt the user for an image file path\n",
        "if __name__ == \"__main__\":\n",
        "    image_path = input(\"Enter the path to the image file: \")\n",
        "    predict_skin_tone(image_path)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "27VN6CADPJJf",
        "outputId": "ead1bfd0-f4f6-4eca-a0d6-54e56204056e"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Enter the path to the image file: /content/test3.png\n",
            "1/1 [==============================] - 1s 863ms/step\n",
            "Predicted Skin Tone: Fair / Light\n",
            "K-Means Dominant Color (BGR): [130 160 218]\n",
            "Saved to: /content/color_result/kmeans_dominant_color.jpg\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import csv\n",
        "\n",
        "# Load the dataset from a CSV file\n",
        "def load_dataset(file_path):\n",
        "    \"\"\"\n",
        "    Load the dataset from a CSV file with the specified structure.\n",
        "    \"\"\"\n",
        "    dataset = []\n",
        "    with open(file_path, mode=\"r\") as file:\n",
        "        reader = csv.DictReader(file)\n",
        "        for row in reader:\n",
        "            skin_tone = [int(row[\"Skin_Tone_R\"]), int(row[\"Skin_Tone_G\"]), int(row[\"Skin_Tone_B\"])]\n",
        "            suited_colors = [\n",
        "                [int(value) for value in color.split(\",\")]\n",
        "                for color in row[\"Suited_Colors\"].split(\";\")\n",
        "            ]\n",
        "            dataset.append({\"skin_tone\": skin_tone, \"suited_colors\": suited_colors})\n",
        "    return dataset\n",
        "\n",
        "# Load the dataset from the specified path\n",
        "dataset = load_dataset(\"/content/expanded_skin_tone_colors.csv\")\n",
        "\n",
        "def find_closest_skin_tones(detected_rgb, threshold=30):\n",
        "    \"\"\"\n",
        "    Find all skin tones within a threshold distance of the detected tone.\n",
        "    \"\"\"\n",
        "    close_tones = []\n",
        "    for entry in dataset:\n",
        "        skin_tone = np.array(entry[\"skin_tone\"])\n",
        "        distance = np.linalg.norm(skin_tone - detected_rgb)  # Euclidean distance\n",
        "        if distance <= threshold:\n",
        "            close_tones.append({\"skin_tone\": entry[\"skin_tone\"], \"suited_colors\": entry[\"suited_colors\"], \"distance\": distance})\n",
        "    # Sort by distance (closest first)\n",
        "    close_tones = sorted(close_tones, key=lambda x: x[\"distance\"])\n",
        "    return close_tones\n",
        "\n",
        "def recommend_colors_multiple(detected_rgb, threshold=30):\n",
        "    \"\"\"\n",
        "    Recommend clothing colors based on detected skin tone and nearby tones.\n",
        "    \"\"\"\n",
        "    close_tones = find_closest_skin_tones(detected_rgb, threshold)\n",
        "    if close_tones:\n",
        "        print(\"\\nRecommended Clothing Colors (RGB):\")\n",
        "        all_recommendations = set()  # Use a set to avoid duplicate colors\n",
        "        for tone in close_tones:\n",
        "            print(f\" \")\n",
        "            for color in tone[\"suited_colors\"]:\n",
        "                all_recommendations.add(tuple(color))  # Add colors to the set\n",
        "        for color in all_recommendations:\n",
        "            print(list(color))  # Print as list for readability\n",
        "    else:\n",
        "        print(\"No matching skin tones found within the threshold.\")\n",
        "\n",
        "# Example: Detected skin tone\n",
        "detected_rgb = np.array([215, 180, 130])  # Example detected tone\n",
        "recommend_colors_multiple(detected_rgb, threshold=40)  # Adjust threshold as needed\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "smrlfUURwaFM",
        "outputId": "8d42a24b-d733-4ea8-a90e-c4b8b6801f73"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Recommended Clothing Colors (RGB):\n",
            " \n",
            " \n",
            "[186, 85, 211]\n",
            "[255, 127, 80]\n",
            "[32, 178, 170]\n",
            "[70, 130, 180]\n",
            "[240, 230, 140]\n",
            "[255, 204, 0]\n",
            "[255, 140, 0]\n",
            "[245, 222, 179]\n",
            "[46, 139, 87]\n",
            "[255, 215, 0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **MINIMUM PRICE FINDER**"
      ],
      "metadata": {
        "id": "jYxMjWxZIjXh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torchvision import models, transforms\n",
        "from PIL import Image\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.cluster import KMeans\n",
        "from collections import Counter\n",
        "\n",
        "# Load a pre-trained model\n",
        "model = models.resnet50(weights=models.ResNet50_Weights.DEFAULT)\n",
        "model.eval()\n",
        "\n",
        "# Define the image transformation\n",
        "preprocess = transforms.Compose([\n",
        "    transforms.Resize(256),\n",
        "    transforms.CenterCrop(224),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Lambda(lambda x: x[:3, :, :]),  # Select the first 3 channels (RGB)\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
        "])\n",
        "\n",
        "# Define a mapping from model output to item categories\n",
        "category_mapping = {\n",
        "    0: 'T-Shirts',\n",
        "    1: 'Shirts',\n",
        "    2: 'Jeans',\n",
        "    3: 'Skirts',\n",
        "    4: 'Dresses',\n",
        "    5: 'Jackets',\n",
        "    6: 'Shorts'\n",
        "}\n",
        "\n",
        "# Define a function to identify the dominant colors in the image\n",
        "def identify_colors(image_path, num_colors=3):\n",
        "    image = Image.open(image_path)\n",
        "    image = image.resize((50, 50))  # Resize for faster processing\n",
        "\n",
        "    # Convert the image to RGB format if it's not already\n",
        "    if image.mode != 'RGB':\n",
        "        image = image.convert('RGB')\n",
        "\n",
        "    pixels = np.array(image).reshape(-1, 3)\n",
        "\n",
        "    # Use K-means clustering to find dominant colors\n",
        "    kmeans = KMeans(n_clusters=num_colors)\n",
        "    kmeans.fit(pixels)\n",
        "    colors = kmeans.cluster_centers_.astype(int)\n",
        "\n",
        "    # Define a comprehensive set of color ranges\n",
        "    color_mapping = {\n",
        "        'Red': [255, 0, 0],\n",
        "        'Green': [0, 255, 0],\n",
        "        'Blue': [0, 0, 255],\n",
        "        'Black': [0, 0, 0],\n",
        "        'White': [255, 255, 255],\n",
        "        'Yellow': [255, 255, 0],\n",
        "        'Purple': [128, 0, 128],\n",
        "        'Orange': [255, 165, 0],\n",
        "        'Pink': [255, 192, 203],\n",
        "        'Brown': [165, 42, 42],\n",
        "        'Gray': [128, 128, 128],\n",
        "        'Light Blue': [173, 216, 230],\n",
        "        'Dark Blue': [0, 0, 139],\n",
        "        'Light Green': [144, 238, 144],\n",
        "        'Dark Green': [0, 100, 0],\n",
        "        'Light Red': [255, 182, 193],\n",
        "        'Dark Red': [139, 0, 0],\n",
        "        'Light Yellow': [255, 255, 224],\n",
        "        'Dark Yellow': [204, 204, 0],\n",
        "        'Cyan': [0, 255, 255],\n",
        "        'Magenta': [255, 0, 255],\n",
        "        'Maroon': [128, 0, 0],\n",
        "        'Olive': [128, 128, 0],\n",
        "        'Teal': [0, 128, 128],\n",
        "        'Navy': [0, 0, 128],\n",
        "        'Silver': [192, 192, 192],\n",
        "        'Gold': [255, 215, 0],\n",
        "        'Beige': [245, 245, 220],\n",
        "        'Lavender': [230, 230, 250],\n",
        "        'Turquoise': [64, 224, 208],\n",
        "        'Peach': [255, 218, 185],\n",
        "        'Mint': [189, 252, 201],\n",
        "        'Coral': [255, 127, 80],\n",
        "        'Indigo': [75, 0, 130],\n",
        "        'Violet': [238, 130, 238],\n",
        "        'Khaki': [240, 230, 140],\n",
        "        'Plum': [221, 160, 221],\n",
        "        'Crimson': [220, 20, 60],\n",
        "        'Salmon': [250, 128, 114],\n",
        "        'Chocolate': [210, 105, 30],\n",
        "        'Tan': [210, 180, 140],\n",
        "        'Orchid': [218, 112, 214],\n",
        "        'Azure': [240, 255, 255],\n",
        "        'Ivory': [255, 255, 240],\n",
        "        'Lime': [0, 255, 0],\n",
        "        'Periwinkle': [204, 204, 255],\n",
        "        'Chartreuse': [127, 255, 0],\n",
        "        'Aquamarine': [127, 255, 212],\n",
        "        'Fuchsia': [255, 0, 255],\n",
        "        'Wheat': [245, 222, 179],\n",
        "        'Lemon': [255, 250, 205],\n",
        "        'Sienna': [160, 82, 45],\n",
        "        'Mauve': [224, 176, 255],\n",
        "        'Rose': [255, 228, 225],\n",
        "        'Burgundy': [128, 0, 32],\n",
        "        'Mustard': [255, 219, 88],\n",
        "        'Copper': [184, 115, 51],\n",
        "        'Bronze': [205, 127, 50],\n",
        "        'Ruby': [224, 17, 95],\n",
        "        'Emerald': [80, 200, 120],\n",
        "        'Sapphire': [15, 82, 186],\n",
        "        'Amber': [255, 191, 0],\n",
        "        'Jade': [0, 168, 107],\n",
        "        'Pearl': [234, 224, 200],\n",
        "        'Onyx': [53, 56, 57],\n",
        "        'Obsidian': [78, 61, 43],\n",
        "        'Topaz': [255, 200, 124],\n",
        "        'Garnet': [115, 54, 53],\n",
        "        'Amethyst': [153, 102, 204],\n",
        "        'Citrine': [228, 208, 10],\n",
        "        'Opal': [168, 195, 188],\n",
        "        'Quartz': [217, 217, 243],\n",
        "        'Spinel': [114, 47, 55],\n",
        "        'Tourmaline': [48, 213, 200],\n",
        "        'Zircon': [95, 158, 160]\n",
        "    }\n",
        "\n",
        "    # Find the closest colors using Euclidean distance\n",
        "    def closest_color(color):\n",
        "        return min(color_mapping.keys(), key=lambda c: np.linalg.norm(color - np.array(color_mapping[c])))\n",
        "\n",
        "    identified_colors = [closest_color(color) for color in colors]\n",
        "\n",
        "    # Count the most common colors\n",
        "    color_counts = Counter(identified_colors)\n",
        "    most_common_colors = [color for color, count in color_counts.most_common(num_colors)]\n",
        "\n",
        "    return most_common_colors\n",
        "\n",
        "def classify_image(image_path):\n",
        "    image = Image.open(image_path)\n",
        "    image = preprocess(image)\n",
        "    image = image.unsqueeze(0)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        outputs = model(image)\n",
        "\n",
        "    _, predicted = outputs.max(1)\n",
        "    category = category_mapping.get(predicted.item(), 'T-Shirts')  # Default to 'T-Shirts' if not found\n",
        "\n",
        "    # Identify the colors of the item\n",
        "    colors = identify_colors(image_path)\n",
        "\n",
        "    return category, colors\n",
        "\n",
        "def extract_features(image_path):\n",
        "    image = Image.open(image_path)\n",
        "    image = preprocess(image)\n",
        "    image = image.unsqueeze(0)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        features = model(image)\n",
        "\n",
        "    return features\n",
        "\n",
        "# Load the fixed sample dataset\n",
        "df = pd.read_csv('updated_sample_database_extended.csv')\n",
        "\n",
        "# Find the minimum price for each item\n",
        "df['Min Price'] = df[['Platform A', 'Platform B', 'Platform C']].min(axis=1)\n",
        "df['Best Platform'] = df[['Platform A', 'Platform B', 'Platform C']].idxmin(axis=1)\n",
        "\n",
        "# Function to find similar items and compare prices\n",
        "def compare_similar_items(item_category, item_colors):\n",
        "    similar_items = df[(df['Item'] == item_category) & (df['Color'].isin(item_colors))]\n",
        "\n",
        "    # Sort by Min Price and select top 5 options with most similarity and best price options\n",
        "    top_similar_items = similar_items.sort_values(by='Min Price').head(5)\n",
        "\n",
        "    return top_similar_items\n",
        "\n",
        "def main(image_path):\n",
        "    # Step 1: Classify the image and identify the colors\n",
        "    category, colors = classify_image(image_path)\n",
        "    print(f'Predicted category: {category}, Colors: {colors}')\n",
        "\n",
        "    # Step 2: Extract features (optional, for more advanced similarity search)\n",
        "    features = extract_features(image_path)\n",
        "\n",
        "    # Step 3: Compare prices of similar items and select top 5 options\n",
        "    top_similar_items = compare_similar_items(category, colors)\n",
        "    print(top_similar_items)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    image_path = 'test3.png'\n",
        "    main(image_path)\n"
      ],
      "metadata": {
        "id": "mHg4XXuTIpWG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **MATCHING OUTFIT**"
      ],
      "metadata": {
        "id": "VWvhRJ5ZSBZm"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "bW6HieieULpW"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}